# Hello-World
You do not need any existing Hive installation to use Sparkâ€™s Hive support. SparkSession context will automatically create metastore_db in the current directory of a Spark application and a directory configured by spark.sql.warehouse.dir.
